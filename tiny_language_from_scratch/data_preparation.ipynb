{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4afa09-105f-4df8-b2c0-567ac7295ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/gillus/llm.c/blob/master/data_preparation.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60710984-2c8e-4aaf-9db9-c91cd2184ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-macosx_10_13_x86_64.whl.metadata (52 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/user/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/user/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/user/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/user/anaconda3/envs/py312/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/user/anaconda3/envs/py312/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.8-cp312-cp312-macosx_10_13_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-macosx_10_13_x86_64.whl (293 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-macosx_10_13_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-macosx_10_13_x86_64.whl (66 kB)\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pyparsing-3.3.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install polars\n",
    "# !pip install --upgrade 'typing_extensions>=4.8.0' pydantic-core ollama\n",
    "# !pip install dotenv\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ac1792-e846-4f74-94c9-ffeff3850154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2933cc39-cb3b-4eec-bde1-efeaa3c9e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>id</th><th>dump</th><th>url</th><th>file_path</th><th>language</th><th>language_score</th><th>token_count</th><th>score</th><th>int_score</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;The Independent Jane\n",
       "For all t…</td><td>&quot;&lt;urn:uuid:0d8a309d-25c5-405d-a…</td><td>&quot;CC-MAIN-2013-20&quot;</td><td>&quot;http://austenauthors.net/the-i…</td><td>&quot;s3://commoncrawl/crawl-data/CC…</td><td>&quot;en&quot;</td><td>0.97432</td><td>845</td><td>2.75</td><td>3</td></tr><tr><td>&quot;Taking Play Seriously\n",
       "By ROBIN…</td><td>&quot;&lt;urn:uuid:316c7af5-14e1-4d0b-9…</td><td>&quot;CC-MAIN-2013-20&quot;</td><td>&quot;http://query.nytimes.com/gst/f…</td><td>&quot;s3://commoncrawl/crawl-data/CC…</td><td>&quot;en&quot;</td><td>0.961459</td><td>1055</td><td>2.5625</td><td>3</td></tr><tr><td>&quot;How do you get HIV?\n",
       "HIV can be…</td><td>&quot;&lt;urn:uuid:a3e140cd-7f25-48c9-a…</td><td>&quot;CC-MAIN-2013-20&quot;</td><td>&quot;http://www.childline.org.uk/Ex…</td><td>&quot;s3://commoncrawl/crawl-data/CC…</td><td>&quot;en&quot;</td><td>0.966757</td><td>136</td><td>3.125</td><td>3</td></tr><tr><td>&quot;CTComms sends on average 2 mil…</td><td>&quot;&lt;urn:uuid:c337bcd8-6aa1-4f2d-8…</td><td>&quot;CC-MAIN-2013-20&quot;</td><td>&quot;http://www.ctt.org/resource_ce…</td><td>&quot;s3://commoncrawl/crawl-data/CC…</td><td>&quot;en&quot;</td><td>0.910602</td><td>3479</td><td>3.234375</td><td>3</td></tr><tr><td>&quot;Hold the salt: UCLA engineers …</td><td>&quot;&lt;urn:uuid:c0b175bb-65fb-420e-a…</td><td>&quot;CC-MAIN-2013-20&quot;</td><td>&quot;http://www.environment.ucla.ed…</td><td>&quot;s3://commoncrawl/crawl-data/CC…</td><td>&quot;en&quot;</td><td>0.924981</td><td>1115</td><td>2.8125</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
       "│ text      ┆ id        ┆ dump      ┆ url       ┆ … ┆ language_ ┆ token_cou ┆ score    ┆ int_score │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ score     ┆ nt        ┆ ---      ┆ ---       │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆ ---       ┆ ---       ┆ f64      ┆ i64       │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ i64       ┆          ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
       "│ The Indep ┆ <urn:uuid ┆ CC-MAIN-2 ┆ http://au ┆ … ┆ 0.97432   ┆ 845       ┆ 2.75     ┆ 3         │\n",
       "│ endent    ┆ :0d8a309d ┆ 013-20    ┆ stenautho ┆   ┆           ┆           ┆          ┆           │\n",
       "│ Jane      ┆ -25c5-405 ┆           ┆ rs.net/th ┆   ┆           ┆           ┆          ┆           │\n",
       "│ For all   ┆ d-a…      ┆           ┆ e-i…      ┆   ┆           ┆           ┆          ┆           │\n",
       "│ t…        ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆           │\n",
       "│ Taking    ┆ <urn:uuid ┆ CC-MAIN-2 ┆ http://qu ┆ … ┆ 0.961459  ┆ 1055      ┆ 2.5625   ┆ 3         │\n",
       "│ Play      ┆ :316c7af5 ┆ 013-20    ┆ ery.nytim ┆   ┆           ┆           ┆          ┆           │\n",
       "│ Seriously ┆ -14e1-4d0 ┆           ┆ es.com/gs ┆   ┆           ┆           ┆          ┆           │\n",
       "│ By ROBIN… ┆ b-9…      ┆           ┆ t/f…      ┆   ┆           ┆           ┆          ┆           │\n",
       "│ How do    ┆ <urn:uuid ┆ CC-MAIN-2 ┆ http://ww ┆ … ┆ 0.966757  ┆ 136       ┆ 3.125    ┆ 3         │\n",
       "│ you get   ┆ :a3e140cd ┆ 013-20    ┆ w.childli ┆   ┆           ┆           ┆          ┆           │\n",
       "│ HIV?      ┆ -7f25-48c ┆           ┆ ne.org.uk ┆   ┆           ┆           ┆          ┆           │\n",
       "│ HIV can   ┆ 9-a…      ┆           ┆ /Ex…      ┆   ┆           ┆           ┆          ┆           │\n",
       "│ be…       ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆           │\n",
       "│ CTComms   ┆ <urn:uuid ┆ CC-MAIN-2 ┆ http://ww ┆ … ┆ 0.910602  ┆ 3479      ┆ 3.234375 ┆ 3         │\n",
       "│ sends on  ┆ :c337bcd8 ┆ 013-20    ┆ w.ctt.org ┆   ┆           ┆           ┆          ┆           │\n",
       "│ average 2 ┆ -6aa1-4f2 ┆           ┆ /resource ┆   ┆           ┆           ┆          ┆           │\n",
       "│ mil…      ┆ d-8…      ┆           ┆ _ce…      ┆   ┆           ┆           ┆          ┆           │\n",
       "│ Hold the  ┆ <urn:uuid ┆ CC-MAIN-2 ┆ http://ww ┆ … ┆ 0.924981  ┆ 1115      ┆ 2.8125   ┆ 3         │\n",
       "│ salt:     ┆ :c0b175bb ┆ 013-20    ┆ w.environ ┆   ┆           ┆           ┆          ┆           │\n",
       "│ UCLA      ┆ -65fb-420 ┆           ┆ ment.ucla ┆   ┆           ┆           ┆          ┆           │\n",
       "│ engineers ┆ e-a…      ┆           ┆ .ed…      ┆   ┆           ┆           ┆          ┆           │\n",
       "│ …         ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆           │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring FineWeb Edu\n",
    "\n",
    "import polars as pl\n",
    "# big download, only run once\n",
    "!wget https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu/resolve/main/sample/10BT/000_00000.parquet\n",
    "x= pl.scan_parquet('./000_00000.parquet')\n",
    "x.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9e2e94-0bdb-48a7-bcaf-b1a1ec89e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pl.scan_parquet(glob.glob('./*_00000.parquet'))\n",
    "x = x.filter((pl.col('token_count')>100)&(pl.col('score')>3.)&(pl.col('language')=='en')&(pl.col('language_score')>0.95))\n",
    "x = x.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7d8bce3-6269-4b72-89f1-326f5ab1f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 125518, number of tokens 139.898675 M\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of texts: {x.shape[0]}, number of tokens {x[\"token_count\"].sum()/1e6} M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb98a6cf-3d5b-40f6-825d-6db19ce2a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only test [:5] rows for local CPU, \n",
    "# Recommend use google colab to run full steps after testing\n",
    "x = x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428611b6-4e24-485d-bbb9-067fb5e50c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our own data annotator!\n",
    "\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "load_dotenv()\n",
    "# API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "\n",
    "# if not API_KEY:\n",
    "#     raise ValueError(\"Google API Key not found. Please set the GOOGLE_API_KEY environment variable or define it in the script.\")\n",
    "\n",
    "# genai.configure(api_key=API_KEY)\n",
    "# MODEL_NAME = \"gemini-1.5-flash-8b\"\n",
    "\n",
    "# Use ollama local model, make sure install and run \"ollama [pull|run] qwen2.5:3b\"\n",
    "MODEL_NAME = \"qwen2.5:3b\"\n",
    "\n",
    "ALLOWED_TOPICS = [\n",
    "    \"Arts & Humanities\",\n",
    "    \"History & Archaeology\",\n",
    "    \"Social Sciences\",\n",
    "    \"Mathematics\",\n",
    "    \"Physical Sciences\",\n",
    "    \"Children entertrainment\",    \n",
    "    \"Computer Science\",\n",
    "    \"Engineering & Technology\",\n",
    "    \"Life Sciences\",\n",
    "    \"Health & Medicine\",\n",
    "    \"Education Studies\",\n",
    "    \"Business & Finance\",\n",
    "    \"Law & Legal Studies\",\n",
    "    \"Environmental Science & Sustainability\",\n",
    "    \"Languages & Linguistics\",\n",
    "    \"Daily Routines & Home Management\",\n",
    "    \"Family & Interpersonal Relationships\",\n",
    "    \"Hobbies, Leisure & Entertainment\",\n",
    "    \"Personal Health, Wellness & Lifestyle\", \n",
    "    \"Work Life & Career\", \n",
    "    \"Consumer Experiences & Personal Finance\",\n",
    "    \"Personal Journeys & Life Events\",\n",
    "    \"Food & Culinary\"    \n",
    "]\n",
    "\n",
    "EDUCATION_LEVEL = [\"primary school\", \"middle school\", \"high school\", \"university degree\", \"PhD degree\"]\n",
    "\n",
    "def classify_text_with_gemini(text_to_classify):\n",
    "    \"\"\"\n",
    "    Uses Ollama qwen2.5:3b to classify text into topic and complexity.\n",
    "\n",
    "    Args:\n",
    "        text_to_classify (str): The text content to classify.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (topic, complexity) or (None, None) if an error occurs.\n",
    "    \"\"\"\n",
    "    # Ensure text is not empty or just whitespace\n",
    "    if not text_to_classify or text_to_classify.isspace():\n",
    "        #print(\"Warning: Skipping empty or whitespace-only text.\")\n",
    "        return None, None\n",
    "\n",
    "    max_length = 15000\n",
    "    if len(text_to_classify) > max_length:\n",
    "        text_to_classify = text_to_classify[:max_length] + \"...\" # Truncate\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following text and determine its primary topic and the educational level typically required to understand it.\n",
    "\n",
    "Text:\n",
    "\"{text_to_classify}\"\n",
    "\n",
    "Instructions:\n",
    "1. Choose the *single best* topic from this list: {ALLOWED_TOPICS}\n",
    "2. Choose the *single most appropriate* education level one would need to properly understand the text: {EDUCATION_LEVEL}\n",
    "3. Provide your answer ONLY in the following JSON format:\n",
    "   {{\"topic\": \"SELECTED_TOPIC\", \"education\": \"SELECTED_EDUCATION\"}}\n",
    "\n",
    "Example Response:\n",
    "{{\"topic\": \"Science\", \"education\": \"high school\"}}\n",
    "\n",
    "Output ONLY the JSON object.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Use local Ollama model\n",
    "        response = ollama.generate(\n",
    "            model=MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            stream=False,\n",
    "            options={\n",
    "                'temperature': 0.1  # Lower temperature for more deterministic classification\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        raw_response_text = response['response'].strip()\n",
    "        \n",
    "        if raw_response_text.startswith(\"```json\"):\n",
    "            raw_response_text = raw_response_text[7:] # Remove ```json\n",
    "        if raw_response_text.endswith(\"```\"):\n",
    "            raw_response_text = raw_response_text[:-3] # Remove ```\n",
    "        raw_response_text = raw_response_text.strip() # Clean whitespace again\n",
    "\n",
    "        # Parse the JSON response\n",
    "        result = json.loads(raw_response_text)\n",
    "        topic = result.get(\"topic\")\n",
    "        education = result.get(\"education\")\n",
    "\n",
    "        # Validate response against allowed categories\n",
    "        if topic not in ALLOWED_TOPICS:\n",
    "            print(f\"Warning: Received invalid topic '{topic}'. Setting to None.\")\n",
    "            topic = None\n",
    "        if education not in EDUCATION_LEVEL:\n",
    "            print(f\"Warning: Received invalid complexity '{education}'. Setting to None.\")\n",
    "            education = None\n",
    "\n",
    "        return topic, education\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Failed to decode JSON response: {raw_response_text}\")\n",
    "        return \"Error: JSON Decode\", \"Error: JSON Decode\"\n",
    "    except ValueError as ve: # Handle potential errors from model generation (e.g., blocked content)\n",
    "         print(f\"Error: Ollama API returned ValueError (potentially blocked content or invalid response structure). Details: {ve}\")\n",
    "         return \"Error: API Value\", \"Error: API Value\"\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return \"Error: API Call\", \"Error: API Call\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f6ec9b-d1fb-47bd-9cdf-0e284fe3ff19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Health & Medicine', 'university degree')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text_with_gemini(\"The Copy Number Variation analysis of a DNA sequence can help characterize tumoroid cells\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c3fc3f-60f0-4b05-abfb-cc53dbfb22e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hobbies, Leisure & Entertainment', 'primary school')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text_with_gemini(\"The itsy bitsy spider went up the water spout\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4791f06-3e8a-4cc4-ba5f-e1c293ed3c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b3882-61eb-44f7-bf23-596b0e13dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "label_categories = [None] * len(x)\n",
    "label_degrees = [None] * len(x)\n",
    "\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    future_to_index = {\n",
    "        executor.submit(classify_text_with_gemini, text): i\n",
    "        for i, text in enumerate(x['text'])\n",
    "    }\n",
    "\n",
    "    # for future in tqdm(concurrent.futures.as_completed(future_to_index), total=10000, desc=\"Classifying Text\"):\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_to_index), total=5, desc=\"Classifying Text\"):\n",
    "        index = future_to_index[future]\n",
    "        try:\n",
    "            result_tuple = future.result()\n",
    "            label_categories[index] = result_tuple[0]\n",
    "            label_degrees[index] = result_tuple[1]\n",
    "        except Exception as exc:\n",
    "            print(f'Row {index} generated an exception: {exc}')\n",
    "            label_categories[index] = \"Error: Future Exception\"\n",
    "            label_degrees[index] = \"Error: Future Exception\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "776344a3-e14e-4786-b6dd-6f973cd7fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.with_columns([\n",
    "    pl.Series(\"label_category\", label_categories),\n",
    "    pl.Series(\"label_degree\", label_degrees)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1f08146-1789-44c9-b6cb-7dd8e5b07f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.write_parquet('simple_english.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0e0e54-9a9a-4e1e-9c87-eb0aeaa7e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x['label_category'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd64b4c-c00b-4a8b-a9f4-f91620fe0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x['label_degree'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb777e94-1381-41e7-8be8-03acd0607a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e3541-5ae9-4a50-aed3-3399b926900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def generate_synthetic_data(sample_text):\n",
    "    \"\"\"\n",
    "    Uses Gemini to generate synthetic data from a sample text. The synthetic data is obtained by summarizing,\n",
    "    paraphrasing, extracting keywords, and creating a creative variant of the text.\n",
    "\n",
    "    Args:\n",
    "        sample_text (str): The sample text on which to base the synthetic data generation.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing synthesized data with the following keys:\n",
    "              - \"summary\": A succinct summary of the text.\n",
    "              - \"paraphrase\": A reworded version of the text.\n",
    "              - \"keywords\": A list of keywords extracted from the text.\n",
    "              - \"synthetic_variant\": A creatively modified variant of the text.\n",
    "              Returns error messages in the dictionary fields if an error occurs.\n",
    "    \"\"\"\n",
    "    # Ensure text is not empty or just whitespace\n",
    "    if not sample_text or sample_text.isspace():\n",
    "        print(\"Warning: Skipping empty or whitespace-only text.\")\n",
    "        return {\n",
    "            \"summary\": None,\n",
    "            \"paraphrase\": None,\n",
    "            \"keywords\": None,\n",
    "            \"synthetic_variant\": None,\n",
    "        }\n",
    "\n",
    "    # Limit text length to avoid exceeding model limits (adjust as needed)\n",
    "    max_length = 15000  # Example limit, adjust based on model token limits if needed\n",
    "    if len(sample_text) > max_length:\n",
    "        sample_text = sample_text[:max_length] + \"...\"  # Truncate\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an advanced language model designed to perform text augmentation. Given the following text, your task is to generate synthetic data by performing these four tasks:\n",
    "\n",
    "1. **Summarization**: Provide a succinct summary of the text.\n",
    "2. **Paraphrasing**: Rephrase the text while preserving its meaning.\n",
    "3. **Synthetic Variant**: Generate one additional variant of the text with creative modifications (e.g. varying sentence structure or introducing subtle stylistic changes).\n",
    "\n",
    "Please provide your answer ONLY in the following JSON format:\n",
    "{{\n",
    "    \"summary\": \"Summarized version of the text.\",\n",
    "    \"paraphrase\": \"Paraphrased version of the text.\",\n",
    "    \"synthetic_variant\": \"Creative synthetic variant of the text.\"\n",
    "}}\n",
    "\n",
    "Example Response:\n",
    "{{\n",
    "    \"summary\": \"A brief summary of the sample text.\",\n",
    "    \"paraphrase\": \"A reworded version of the sample text.\",\n",
    "    \"synthetic_variant\": \"An alternative version of the text with creative modifications.\"\n",
    "}}\n",
    "\n",
    "Text:\n",
    "\\\"{sample_text}\\\"\n",
    "\n",
    "Output ONLY the JSON object.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")  # Replace with your actual model name\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=0.2,  # Adjust temperature to balance creativity and fidelity\n",
    "                # You can also fine-tune the max output tokens if necessary, e.g.\n",
    "                # max_output_tokens=150,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        raw_response_text = response.text.strip()\n",
    "        # Remove markdown formatting if present\n",
    "        if raw_response_text.startswith(\"```json\"):\n",
    "            raw_response_text = raw_response_text[7:]\n",
    "        if raw_response_text.endswith(\"```\"):\n",
    "            raw_response_text = raw_response_text[:-3]\n",
    "        raw_response_text = raw_response_text.strip()\n",
    "\n",
    "        # Parse the JSON response\n",
    "        result = json.loads(raw_response_text)\n",
    "        # Optionally, validate that required keys are present\n",
    "        for key in [\"summary\", \"paraphrase\", \"synthetic_variant\"]:\n",
    "            if key not in result:\n",
    "                print(f\"Warning: Expected key '{key}' not found in the output. Setting its value to None.\")\n",
    "                result[key] = None\n",
    "\n",
    "        return result\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Failed to decode JSON response: {raw_response_text}\")\n",
    "        return {\n",
    "            \"summary\": \"Error: JSON Decode\",\n",
    "            \"paraphrase\": \"Error: JSON Decode\",\n",
    "            \"synthetic_variant\": \"Error: JSON Decode\",\n",
    "        }\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error: Gemini API returned ValueError. Raw response: {response.text if 'response' in locals() else 'N/A'}. Details: {ve}\")\n",
    "        return {\n",
    "            \"summary\": \"Error: API Value\",\n",
    "            \"paraphrase\": \"Error: API Value\",\n",
    "            \"synthetic_variant\": \"Error: API Value\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return {\n",
    "            \"summary\": \"Error: API Call\",\n",
    "            \"paraphrase\": \"Error: API Call\",\n",
    "            \"synthetic_variant\": \"Error: API Call\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b54e55-b276-4d97-a271-c9b5b2d5b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_synthetic_data(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464ecc3f-b798-4699-b9a3-33ba475690ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arts & Humanities',\n",
       " 'Business & Finance',\n",
       " 'Children entertrainment',\n",
       " \"Children's Education\",\n",
       " 'Computer Science',\n",
       " 'Consumer Experiences & Personal Finance',\n",
       " 'Cultural Studies',\n",
       " 'Daily Routines & Home Management',\n",
       " 'Education Studies',\n",
       " 'Engineering & Technology',\n",
       " 'Entomology',\n",
       " 'Environmental Science & Sustainability',\n",
       " 'Family & Interpersonal Relationships',\n",
       " 'Food & Culinary',\n",
       " 'Health & Medicine',\n",
       " 'History & Archaeology',\n",
       " 'Hobbies, Leisure & Entertainment',\n",
       " 'Languages & Linguistics',\n",
       " 'Law & Legal Studies',\n",
       " 'Life Sciences',\n",
       " 'Mathematics',\n",
       " 'Personal Health, Wellness & Lifestyle',\n",
       " 'Personal Journeys & Life Events',\n",
       " 'Physical Sciences',\n",
       " 'Religion & Spirituality',\n",
       " 'Social Sciences',\n",
       " 'Work Life & Career']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALLOWED_TOPICS = [\n",
    "    \"Arts & Humanities\",\n",
    "    \"History & Archaeology\",\n",
    "    \"Social Sciences\",\n",
    "    \"Mathematics\",\n",
    "    \"Physical Sciences\",\n",
    "    \"Children entertrainment\",    \n",
    "    \"Computer Science\",\n",
    "    \"Engineering & Technology\",\n",
    "    \"Life Sciences\",\n",
    "    \"Health & Medicine\",\n",
    "    \"Education Studies\",\n",
    "    \"Business & Finance\",\n",
    "    \"Law & Legal Studies\",\n",
    "    \"Environmental Science & Sustainability\",\n",
    "    \"Languages & Linguistics\",\n",
    "    \"Daily Routines & Home Management\",\n",
    "    \"Family & Interpersonal Relationships\",\n",
    "    \"Hobbies, Leisure & Entertainment\",\n",
    "    \"Personal Health, Wellness & Lifestyle\", \n",
    "    \"Work Life & Career\", \n",
    "    \"Consumer Experiences & Personal Finance\",\n",
    "    \"Personal Journeys & Life Events\",\n",
    "    \"Food & Culinary\",\n",
    "    \"Religion & Spirituality\",\n",
    "    \"Children's Education\",\n",
    "    \"Cultural Studies\",\n",
    "    'Entomology'\n",
    "]\n",
    "sorted(ALLOWED_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c48cc1-224f-4f01-a462-42f3ef3f59dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
